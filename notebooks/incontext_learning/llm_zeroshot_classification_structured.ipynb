{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025017f5",
   "metadata": {},
   "source": [
    "# Zero-shot text classification with LLMs\n",
    "\n",
    "This notebook illustrates how to use `pydantic` and JSON schemas to generate **structured outputs** with different LLMs for text classification.\n",
    "\n",
    "- closed-source LLMs models by OpenAI\n",
    "- open-weights model hosted via Hugging Face Inference Providers/Endpoints\n",
    "- open-weights LLMs models with `ollama`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5afba0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da313a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from src.utils.io import read_tabular\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Literal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f56a5d",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d6e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = False # no support for colab yet\n",
    "base_path = Path(\"/content/advanced_text_analysis/\" if COLAB else \"../../\")\n",
    "data_path = base_path / \"data\" / \"labeled\" / \"benoit_crowdsourced_2016\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8fc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (down)load the data\n",
    "fp = data_path / \"benoit_crowdsourced_2016-policy_area.csv\"\n",
    "if not fp.exists():\n",
    "    url = \"https://cta-text-datasets.s3.eu-central-1.amazonaws.com/labeled/\" + fp.parent.name + '/' + fp.name\n",
    "    df = pd.read_csv(url)\n",
    "    fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(fp, index=False)\n",
    "\n",
    "df = read_tabular(fp, columns=['uid', 'text', 'label', 'metadata__gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5990bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to gold examples (i.e., those labeled by experts)\n",
    "df = df[df.metadata__gold]\n",
    "del df['metadata__gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8944ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    2: 'economic',\n",
    "    3: 'social',\n",
    "    1: 'neither',\n",
    "}\n",
    "df.label = df.label.map(id2label)\n",
    "\n",
    "print(df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562dda17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get five examples per label class\n",
    "expls = df.groupby('label').sample(20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = expls.text.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e11918",
   "metadata": {},
   "source": [
    "## Define the task\n",
    "\n",
    "In this example, we adapt the instruction for one of the tweet classification tasks examined in Benoit et al. ([2016](https://doi.org/10.1017/S0003055416000058)) \"Crowd-sourced Text Analysis: Reproducible and Agile Production\n",
    "of Political Data\"\n",
    "\n",
    "- see [this README file](../../data/labeled/benoit_crowdsourced_2016/README.md) for a description of the data and tasks covered in the paper\n",
    "- see [this file](../../data/labeled/benoit_crowdsourced_2016/instructions/econ_social_policy.md) for a copy of their original task instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4f05ae",
   "metadata": {},
   "source": [
    "#### Using structured outputs\n",
    "\n",
    "Let's say, in addtion to the classification, we also want an **explantation/justification**.\n",
    "Then the output becomes more **complex** than a single label.\n",
    "\n",
    "In this scenario, it is a **best practice** to define an output class that can be passed to the LLM to generate and adequately formatted response.\n",
    "\n",
    "This is done by defining a class that represents the desired structure of the output.\n",
    "This information is then passed as a JSON schema to the LLM and applied as a decoding constraint when generating next tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac91fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pydantic model for the response\n",
    "\n",
    "# the `ClassificationResponse` response model defines the structure of the expected output from the LLM.\n",
    "# It includes two fields: `category`, which can take one of three literal values ('economic', 'social', 'neither'),\n",
    "# and `explanation`, which is a string providing a one-sentence justification for the classification.\n",
    "class ClassificationResponse(BaseModel):\n",
    "    category: Literal['economic', 'social', 'neither'] = Field(..., description=\"The category assigned to the sentence\")\n",
    "    explanation: str = Field(..., description=\"A one-sentence justification for the classification\")\n",
    "\n",
    "# we can get and look at the corresponding JSON schema for the response model\n",
    "json_schema = ClassificationResponse.model_json_schema()\n",
    "print(json_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbc4527",
   "metadata": {},
   "source": [
    "*Note:* the example of adding a post-hoc explanation here is just an example. See [this notebook](./structured_generation_outlines_demo.ipynb) for more and better examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa384e7",
   "metadata": {},
   "source": [
    "**Important:** Now we also need to instruction the model to add an explanation and return a JSON (instead of only the chosen category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = f\"\"\"\n",
    "Act as a text classification system versatile in performing content analysis.\n",
    "\n",
    "You will read a sentence from a political text.\n",
    "Yout will judge whether this sentence deals with economic or social policy.\n",
    "You must classify posts into one of the following categories: \"economic\", \"social\", or \"neither\". \n",
    "\n",
    "## Definitions\n",
    "\n",
    "These categories have the following definitions:\n",
    "\n",
    "- Sentences should be coded as \"economic\" if they deal with aspects of the economy, such as: Taxation, Government spending, Services provided by the government or other public bodies, Pensions, unemployment and welfare benefits, and other state benefits, Property, investment and share ownership, public or private, Interest rates and exchange rates, Regulation of economic activity, public or private, Relations between employers, workers and trade unions\n",
    "- Sentences should be coded as \"social\" if they deal with aspects of social and moral life, relationships between social groups, and matters of national and social identity. These include: Policing, crime, punishment and rehabilitation of offenders; Immigration, relations between social groups, discrimination and multiculturalism; The role of the state in regulating the social and moral behavior of individuals\n",
    "\n",
    "## Step-by-step instructions\n",
    "\n",
    "Follow these steps to classify the sentence:\n",
    "\n",
    "1. Carefully read the text of the sentence, paying close attention to details.\n",
    "2. Assess whether the sentence belongs to any of the categories. If not, return 'neither' as your response.\n",
    "3. Classify the sentence with the category it belongs to. \n",
    "4. Add a one-sentence justification for your classification.\n",
    "\n",
    "## Response format\n",
    "\n",
    "Return your response as a JSON dictionary with the following fields:\n",
    "- \"category\": the category you assigned to the sentence, one of \"economic\", \"social\", or \"neither\"\n",
    "- \"explanation\": a one-sentence justification for your classification\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9773717a",
   "metadata": {},
   "source": [
    "## With ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90464e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "MODEL = 'gpt-4o-2024-08-06'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d1d75",
   "metadata": {},
   "source": [
    "#### illustration without passing a JSON schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e912bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.text.iloc[5]\n",
    "print(text)\n",
    "\n",
    "messages = [\n",
    "    # system prompt\n",
    "    {\"role\": \"system\", \"content\": instructions},\n",
    "    # user input\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.001,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91355dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be6603",
   "metadata": {},
   "source": [
    "This is not what we want. We only need the JSON dictionary without the sourroundung ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f1193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.text.iloc[5]\n",
    "print(text)\n",
    "\n",
    "messages = [\n",
    "    # system prompt\n",
    "    {\"role\": \"system\", \"content\": instructions},\n",
    "    # user input\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.parse(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.001,\n",
    "    seed=42,\n",
    "    response_format=ClassificationResponse,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7828d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the parsed output\n",
    "parsed_output = response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def1d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "print(\"\\033[1mcategory:\\033[0m\", repr(output.category))\n",
    "print(\"\\033[1mexplanation:\\033[0m\", textwrap.fill(output.explanation, width=70, subsequent_indent='    '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596973d",
   "metadata": {},
   "source": [
    "**TODO** Create a function we can use to iterate over multiple examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bd7288",
   "metadata": {},
   "source": [
    "## With Hugging Face _Inference Providers_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de141bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "MODEL = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "client = InferenceClient(MODEL, token=os.environ.get(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cc7e19",
   "metadata": {},
   "source": [
    "the **cool thing** is that the `InferenceClient` works exactly like the `openai.Client` class.\n",
    "So the code from above really _doesn't change_!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7756baf6",
   "metadata": {},
   "source": [
    "For hugging face Client, the response formatting requires a different approach (in current version ): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2175c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub.inference._generated.types.chat_completion import (\n",
    "    ChatCompletionInputResponseFormatJSONSchema, \n",
    "    ChatCompletionInputJSONSchema\n",
    ")\n",
    "\n",
    "hf_json_schema = ChatCompletionInputJSONSchema(name=\"extracted pledge statements JSON schema\", schema=json_schema)\n",
    "hf_response_format =ChatCompletionInputResponseFormatJSONSchema(type=\"json_schema\", json_schema=hf_json_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9161708",
   "metadata": {},
   "source": [
    "#### illustration with a _single_ sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227681fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.text.iloc[5]\n",
    "print(text)\n",
    "\n",
    "messages = [\n",
    "    # system prompt\n",
    "    {\"role\": \"system\", \"content\": instructions},\n",
    "    # user input\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.001,\n",
    "    seed=42,\n",
    "    response_format=hf_response_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f02037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the output\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ee1ff1",
   "metadata": {},
   "source": [
    "This is a JSON. We need to parse it first with out output class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53000485",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ClassificationResponse.model_validate_json(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11389ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1mcategory:\\033[0m\", repr(output.category))\n",
    "print(\"\\033[1mexplanation:\\033[0m\", textwrap.fill(output.explanation, width=70, subsequent_indent='    '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980598eb",
   "metadata": {},
   "source": [
    "Tada! ðŸŽ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6845ec56",
   "metadata": {},
   "source": [
    "## With Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e180bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "client = Client()\n",
    "MODEL = 'gemma3:4b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.text.iloc[5]\n",
    "print(text)\n",
    "messages = [\n",
    "    # system prompt\n",
    "    {\"role\": \"system\", \"content\": instructions},\n",
    "    # user input\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    "]\n",
    "\n",
    "# set some options controlling generation behavior\n",
    "# NOTE: this changed slightly compared to using `openai` Client\n",
    "opts = {\n",
    "    'seed': 42,\n",
    "    'temperature': 0.0,\n",
    "}\n",
    "# NOTE: this changed slightly compared to using `openai` Client\n",
    "response = client.chat(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    options=opts,\n",
    "    format=json_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d362bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ClassificationResponse.model_validate_json(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642052ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1mcategory:\\033[0m\", repr(output.category))\n",
    "print(\"\\033[1mexplanation:\\033[0m\", textwrap.fill(output.explanation, width=70, subsequent_indent='    '))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced_text_analysis_gesis_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
