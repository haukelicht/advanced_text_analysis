{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025017f5",
   "metadata": {},
   "source": [
    "# Few-shot text classification with Llama 3.1 8B and ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676afdc0",
   "metadata": {},
   "source": [
    "For **running on _Google Colab_**, see notebook [llm_zeroshot_classification_ollama.ipynb](./llm_zeroshot_classification_ollama.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da313a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ollama import Client\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd88ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the ollama client that communicates with the `ollama` server running in the background\n",
    "client = Client()\n",
    "MODEL = 'llama3.1:8b' # maybe try 'mistral-nemo:12b' for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44927e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_available_models = lambda : [m['model'] for m in client.list()['models']]\n",
    "\n",
    "if MODEL not in get_available_models():\n",
    "  print(f\"Model not found. Running `client.pull('{MODEL}')` to download it.\")\n",
    "  client.pull(MODEL)\n",
    "\n",
    "# confirm\n",
    "assert MODEL in get_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32c73c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('..', 'data', 'labeled', 'benoit_crowdsourced_2016', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c6f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e11918",
   "metadata": {},
   "source": [
    "## Define the task\n",
    "\n",
    "In this example, we adapt the instruction for the economic/social/neither policy area classification task in Benoit et al. (2016)\n",
    "\n",
    "- see [this README file](../data/labeled/benoit_crowdsourced_2016/README.md) for a description of the data and tasks covered in the paper\n",
    "- see [this file](../data/labeled/benoit_crowdsourced_2016/instructions/econ_social_policy.md) for a copy of their original task instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c19a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "This task involves reading sentences from political texts and judging whether these deal with economic or social policy.\n",
    "\n",
    "The sentences you will be asked to interpret come from political party manifestos.\n",
    "Some of these sentences will deal with economic policy; some will deal with social policy; other sentences will deal with neither economic nor social policy. We tell you below about what we mean by \"economic\" and \"social\" policy.\n",
    "\n",
    "First, you will read a short section from a party manifesto.\n",
    "For the sentence highlighted in red, enter your best judgment about whether it mainly refers to economic policy, to social policy, or to neither.\n",
    "\n",
    "If the sentence refers to economic policy, select \"economic\" in the drop down menu; if it refers to social policy, select \"social\".\n",
    "If the sentence does not refer to either policy area, select \"Not Economic or Social\" -- in this case you will move directly to the next sentence.\n",
    "\n",
    "Now we need to tell you about what we mean by \"economic\" and \"social\" policy.\n",
    "\n",
    "## Your task\n",
    "\n",
    "Classify the input text in one of the following categories: economic, social, neither\n",
    "\n",
    "## Response format\n",
    "\n",
    "Only respond with the chosen category and no additional text or explanations \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092f2b49",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d65075f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import read_tabular\n",
    "from utils.finetuning import split_data\n",
    "\n",
    "fp = data_path+'benoit_crowdsourced_2016-policy_area.csv'\n",
    "df = read_tabular(fp, columns=['text', 'label', 'metadata__gold'])\n",
    "\n",
    "df = df[df.metadata__gold]\n",
    "del df['metadata__gold']\n",
    "\n",
    "id2label = {\n",
    "    2: \"economic\",\n",
    "    3: \"social\",\n",
    "    1: \"neither\"\n",
    "}\n",
    "\n",
    "df.label = df.label.map(id2label)\n",
    "\n",
    "# subset to 100 examples per label class \n",
    "df = df.groupby('label').sample(n=50, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1093ce27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "economic    50\n",
       "neither     50\n",
       "social      50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "765f7c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into \"training\" and \"test\" data\n",
    "#  - training is used for examples\n",
    "#  - test is used for few-shot classification  \n",
    "# note: if you had different example selection \n",
    "#  strategies of variations of a prompt, you could use a dev for comparing them\n",
    "data_splits = split_data(df, test_size=0.5, dev_size=None, stratify_by='label', return_dict=True)\n",
    "data_splits.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9773717a",
   "metadata": {},
   "source": [
    "## sample examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca568f2d",
   "metadata": {},
   "source": [
    "There is various different ways of sampling few-shot exemplars\n",
    "\n",
    "Here, we take the **most representative exemplars** by \n",
    "\n",
    "1. embedding exemplars\n",
    "2. computing the centroid for each label class\n",
    "3. and ranking exemplars in terms of their closeness to their class centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9cc8055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "def embed(texts: List[str]):\n",
    "    # see https://platform.openai.com/docs/guides/embeddings/what-are-embeddings?lang=python\n",
    "    texts = [text.replace(\"\\n\", \" \") for text in texts] \n",
    "    res = client.embed(\n",
    "        input=texts,\n",
    "        model=MODEL\n",
    "        # alternatively, take 'mxbai-embed-large' for faster embedding\n",
    "    )\n",
    "    return np.array(res['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ec6fb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcabb845a03842b4ab770164a7a52f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "ranked_exemplars = {}\n",
    "for label_class, df in tqdm(data_splits['train'].groupby('label')):\n",
    "    # get embeddings from OpenAI model\n",
    "    embeddings = embed(df.text.to_list())\n",
    "    # compute centroid\n",
    "    centroid = embeddings.mean(axis=0)\n",
    "    # compute cosine similarity between the centroid and the embeddings\n",
    "    dists = cosine_similarity([centroid], embeddings)\n",
    "    # rank the examples by similarity, descending\n",
    "    ranked_indices = np.argsort(dists[0])[::-1]\n",
    "    # add to output\n",
    "    ranked_exemplars[label_class]= df.iloc[ranked_indices, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a45eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_n_examples(ranked_exemplars, k, shuffle=True, random_state=SEED):\n",
    "    exs = []\n",
    "    for label_class, exemplars in ranked_exemplars.items():\n",
    "        ex = exemplars[:k].to_list()\n",
    "        ex = [{'text': text, 'label': label_class} for text in ex]\n",
    "        exs.extend(ex)\n",
    "    if shuffle:\n",
    "        random.Random(random_state).shuffle(exs)\n",
    "    return exs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a9d4d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Rigid dogmas, the overriding need for party unity, and indiscriminate three-line whips have all helped to create a climate of conflict and rancour.',\n",
       "  'label': 'neither'},\n",
       " {'text': 'We will encourage the recruitment of ethnic minorities into the police force and require action to be taken against discrimination within the force.',\n",
       "  'label': 'social'},\n",
       " {'text': 'We have encouraged tougher sentences for violent criminals.',\n",
       "  'label': 'social'},\n",
       " {'text': 'We seek the support of the British people to make this achievement truly secure, to build upon it and to extend its benefits to all.',\n",
       "  'label': 'neither'},\n",
       " {'text': 'We will strengthen the law on public order to combat racial hatred and take firm action against the growing menace of racial attacks.',\n",
       "  'label': 'social'},\n",
       " {'text': 'In particular, we will cut income tax still further and reduce the basic rate to 25p in the Â£ as soon as we prudently can.',\n",
       "  'label': 'economic'},\n",
       " {'text': 'From the White House through Europe to the Kremlin our voice is heard on arms control, on East-West issues, on human rights, on the Middle East and on African affairs.',\n",
       "  'label': 'neither'},\n",
       " {'text': 'We will continue to reduce the burden of capital gains tax and inheritance tax as it is prudent to do so.',\n",
       "  'label': 'economic'},\n",
       " {'text': 'We will cut the small companies rate of corporation tax in line with personal taxation as we move towards a 20p basic rate.',\n",
       "  'label': 'economic'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_examples(ranked_exemplars, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "465f900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_exemplars_list_to_convo(exemplars):\n",
    "    convo = []\n",
    "    for ex in exemplars:\n",
    "        convo.append({\"role\": \"user\", \"content\": f\"'''{ex['text']}'''\"},)\n",
    "        convo.append({\"role\": \"assistant\", \"content\": ex['label']},)\n",
    "    return convo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35819e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"'''Rigid dogmas, the overriding need for party unity, and indiscriminate three-line whips have all helped to create a climate of conflict and rancour.'''\"},\n",
       " {'role': 'assistant', 'content': 'neither'},\n",
       " {'role': 'user',\n",
       "  'content': \"'''We will encourage the recruitment of ethnic minorities into the police force and require action to be taken against discrimination within the force.'''\"},\n",
       " {'role': 'assistant', 'content': 'social'},\n",
       " {'role': 'user',\n",
       "  'content': \"'''We have encouraged tougher sentences for violent criminals.'''\"},\n",
       " {'role': 'assistant', 'content': 'social'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_exemplars_list_to_convo(get_n_examples(ranked_exemplars, 3))[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7520f9",
   "metadata": {},
   "source": [
    "### A single text example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed4861eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = data_splits['test'].text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "647308d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to conversation history\n",
    "messages = [\n",
    "  # system prompt\n",
    "  {\"role\": \"system\", \"content\": instructions},\n",
    "  # exemplars\n",
    "  *convert_exemplars_list_to_convo(get_n_examples(ranked_exemplars, 3))[:6],\n",
    "  # user input\n",
    "  {\"role\": \"user\", \"content\": f\"'''{text_input}'''\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2189ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = options = {'seed': 42, 'temperature': 0.0, 'max_tokens': 3}\n",
    "response = client.chat(\n",
    "  model=MODEL,\n",
    "  messages=messages,\n",
    "  options=options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6cc4b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': 'economic'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the response\n",
    "response['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7709d230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'economic'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_splits['test'].label.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596973d",
   "metadata": {},
   "source": [
    "### Iterate over multiple examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373b62c",
   "metadata": {},
   "source": [
    "Let's first define a custom function to classify tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fb21f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "def classify_tweet(text, model: str, system_message: str, exemplars: List[Dict]):\n",
    "\n",
    "  # clean the text \n",
    "  text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "  # construct input\n",
    "\n",
    "  messages = [\n",
    "    # system prompt\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    # exemplars\n",
    "    *convert_exemplars_list_to_convo(exemplars),\n",
    "    # user input\n",
    "    {\"role\": \"user\", \"content\": f\"'''{text}'''\"},\n",
    "  ]\n",
    "\n",
    "  options = options = {'seed': 42, 'temperature': 0.0, 'max_tokens': 3}\n",
    "  response = client.chat(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    options=options\n",
    "  )\n",
    "  \n",
    "  if 'message' not in response:\n",
    "      print(\"WARNING: Response should have one 'meassage'\")\n",
    "      return None\n",
    "  if not response['done'] or response['done_reason'] != 'stop':\n",
    "      print(\"WARNING: Response should have 'done_reason' of 'stop' but got:\", response['done_reason'])\n",
    "      return None\n",
    "\n",
    "  return response['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6788aed",
   "metadata": {},
   "source": [
    "Now we can iterate over example texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22799dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e7f6fbab2e4f0398cf5e45aab3aeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "texts = data_splits['test'].text.to_list()\n",
    "exemplars = get_n_examples(ranked_exemplars, 3)\n",
    "classifications = [classify_tweet(text, model=MODEL, system_message=instructions, exemplars=exemplars) for text in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d2c02f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economic       1.00      0.32      0.48        25\n",
      "     neither       0.85      0.92      0.88        25\n",
      "      social       0.60      0.96      0.74        25\n",
      "\n",
      "    accuracy                           0.73        75\n",
      "   macro avg       0.82      0.73      0.70        75\n",
      "weighted avg       0.82      0.73      0.70        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr = classification_report(\n",
    "    y_true = data_splits['test'].label.to_list(),\n",
    "    y_pred = classifications\n",
    ")\n",
    "\n",
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_text_annotation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
